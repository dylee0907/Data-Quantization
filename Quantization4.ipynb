{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Post-Training Static Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static quantization은 각 층의 Activation에 대한 clipping range가 input tensor값에 상관없이 고정(fixed, static)되어 있는 경우이다.\n",
    "\n",
    "입력값(예를 들어, 입력 이미지)에 따라서 각 층의 activation값이 변화하므로 sampling data를 이용해서 각 층의 activation에 대한 clipping range에 대한 수치를 수집한 후에, 최빈값(가장 빈도수가 많은 값)으로 quantization parameter를 정하게 된다.\n",
    "\n",
    "PyTorch의 경우, 딥러닝 모델에서 각 층의 activation값을 추출하는 것은 register_forward_hook이라는 방법을 이용한다.\n",
    "\n",
    "예를 들어, 100개의 서로 다른 입력값에 대해서 모델의 각 층의 activation값과 이에 따른 quantization parameter(scaling factor)를 구하고, quantization parameter 중에서 최빈도값을 최종 quantization parameter로 결정한 후에, 이 값을 이용해서 모델의 각 층의 activation값을 양자화하게 된다.\n",
    "\n",
    "이 경우에 입력값에 따라 clipping range를 보정하는 과정이 딥러닝 모델의 수행 과정 중에 포함되지 않는 장점이 있지만, 입력값에 따라 정해진 clipping range가 맞지 않을 경우에는 모델의 예측값이 맞지 않을 가능성이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import pickle\n",
    "#import time\n",
    "#import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available! Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output: model output\n",
    "#target: correct answer\n",
    "#topk: number of k best model output\n",
    "\n",
    "def accuracy(output, target ,topk=(1,)):\n",
    "  \"\"\"\n",
    "  Computes the accuracy over the k top predictions for the specified values of k\n",
    "  IN top-5 accuracy you give yourself credit for having the right answer\n",
    "  if the right answer appears in your top five guesses\n",
    "  \"\"\"\n",
    "  with torch.no_grad(): #no need for gradient\n",
    "    maxk = max(topk) #store biggest topk value\n",
    "    batch_size=target.size(0) #check batch size // express \"target\" tensor's 0th dimension size\n",
    "\n",
    "    _, pred = output.topk(maxk,1,True,True) #maxk=bring upper k value / dim=selected class dimension / 1st True=largest, if smallest use False / 2nd True=sort result? yes=True, no=False\n",
    "    pred = pred.t() #transpose tensor pred\n",
    "\n",
    "    #correct = pred.eq(target. view(1, -1).expand_as(pred))\n",
    "    #correct = (pred == target.view(1, -1).expand_as(pred))\n",
    "    correct = (pred == target.unsqueeze(dim=0)).expand_as(pred)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      #correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul(1.0/batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "  def __init__(self, name, fmt=':f'): #floating point format\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.val=0\n",
    "    self.avg=0\n",
    "    self.sum=0\n",
    "    self.count=0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.num / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "    #fmtstr = '{name} {val' + self.fmt + '}({avg' + self.fmt+ '})'\n",
    "    fmtstr = '{name} ({avg' + self.fmt +  '})'\n",
    "\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def norm1(X,Y):\n",
    "  return np.sum(np.abs(X-Y))\n",
    "\n",
    "def norm2(X,Y):\n",
    "  return np.sqrt(np.sum(np.square(X-Y)))\n",
    "\n",
    "def quantize(X, NBIT=8):\n",
    "    #symmetry quantization, per tensor\n",
    "    #1. find threshold\n",
    "    threshold = np.max([np.abs(np.max(X)), np.abs(np.min(X))])\n",
    "\n",
    "    QRANGE = 2**(NBIT-1)\n",
    "\n",
    "    #2. find p: decimal position of quantized value\n",
    "    p = np.int(np.log2((QRANGE-1)/threshold))\n",
    "\n",
    "    #3. quantize using 8 bit\n",
    "    #3.1 apply threshold\n",
    "    data_th = np.clip(X, -QRANGE*2**(-p), (QRANGE-1)*2**(-p))\n",
    "\n",
    "    #3.2 calculate the scale factor for quantization\n",
    "    SCALE = 2**(-p)\n",
    "\n",
    "    #3.3 quantize (apply scale factor)\n",
    "    #we are using a rounding function to force the quantized values to be the whole numbers which INT8 can represent\n",
    "    data_qn = np.round(data_th/SCALE)\n",
    "\n",
    "    #3.4 dequantize (simply reverse the quantization)\n",
    "    data_dqn = data_qn *SCALE\n",
    "    return data_dqn, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Dynamic Quantized Model after activation**\n",
    "\n",
    "needs torch version >=1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet19(nn.Module): # formal inheritance method in PyTorch / inherit Parent class nn.Module\n",
    "  def __init__(self, num_classes: int = 1000): # 1000 is number of classes for neuralnet model to predict. It is default. you can reset it when calling the function\n",
    "    super(Darknet19, self).__init__() # super(child class name, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False) #3*3 require zero padding / 1*1 does not require zero padding\n",
    "    self.batchnorm1 = nn.BatchNorm2d(32) #32개 channel 출력값을 normalization, Z function(평균, 분산)-->(0,1) gradient vanishing, exploding을 방지\n",
    "    self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.1) #Relu negative slope\n",
    "\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "    self.leaky_relu2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "    self.leaky_relu4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu6 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm7 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu7 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm8 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu8 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm9 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu9 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm10 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu10 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm11 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu11 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm12 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu12 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv13 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm13 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu13 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm14 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu14 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm15 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu15 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm16 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu16 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm17 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu17 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm18 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu18 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv19 = nn.Conv2d(in_channels=1024, out_channels=num_classes, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "    self.avgpool= nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.max_pool2d=nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out=self.batchnorm1(self.conv1(x))\n",
    "    out=self.leaky_relu1(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm2(self.conv2(out))\n",
    "    out=self.leaky_relu2(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm3(self.conv3(out))\n",
    "    out=self.leaky_relu3(out)\n",
    "    out=self.batchnorm4(self.conv4(out))\n",
    "    out=self.leaky_relu4(out)\n",
    "    out=self.batchnorm5(self.conv5(out))\n",
    "    out=self.leaky_relu5(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm6(self.conv6(out))\n",
    "    out=self.leaky_relu6(out)\n",
    "    out=self.batchnorm7(self.conv7(out))\n",
    "    out=self.leaky_relu7(out)\n",
    "    out=self.batchnorm8(self.conv8(out))\n",
    "    out=self.leaky_relu8(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm9(self.conv9(out))\n",
    "    out=self.leaky_relu9(out)\n",
    "    out=self.batchnorm10(self.conv10(out))\n",
    "    out=self.leaky_relu10(out)\n",
    "    out=self.batchnorm11(self.conv11(out))\n",
    "    out=self.leaky_relu11(out)\n",
    "    out=self.batchnorm12(self.conv12(out))\n",
    "    out=self.leaky_relu12(out)\n",
    "    out=self.batchnorm13(self.conv13(out))\n",
    "    out=self.leaky_relu13(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm14(self.conv14(out))\n",
    "    out=self.leaky_relu14(out)\n",
    "    out=self.batchnorm15(self.conv15(out))\n",
    "    out=self.leaky_relu15(out)\n",
    "    out=self.batchnorm16(self.conv16(out))\n",
    "    out=self.leaky_relu16(out)\n",
    "    out=self.batchnorm17(self.conv17(out))\n",
    "    out=self.leaky_relu17(out)\n",
    "    out=self.batchnorm18(self.conv18(out))\n",
    "    out=self.leaky_relu18(out)\n",
    "\n",
    "    out=self.conv19(out)\n",
    "    out=self.avgpool(out)\n",
    "    out=torch.flatten(out,1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, weight_path, output_layers, *args):\n",
    "        super().__init__(*args)\n",
    "        self.output_layers = output_layers\n",
    "        self.selected_out = OrderedDict()\n",
    "        self.pretrained = Darknet19()\n",
    "        self.pretrained.load_state_dict(torch.load(weight_path))\n",
    "        self.fhooks = []\n",
    "\n",
    "        for i,l in enumerate(list(self.pretrained._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.pretrained,l).register_forward_hook(self.forward_hook(1)))\n",
    "\n",
    "    def forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "        return hook            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        return out, self.selected_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = './darknet19_quan_weight1.pth'\n",
    "model = NewModel(weight_path, output_layers = [i for i in range(60)]).to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\\wrk\\xsjhdnobkup5\\taeheej\\dataset\\imagenet\"\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val3k')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1,1,1]) #scale[0,1]--->normalization unpreceded\n",
    "\n",
    "batch_size=32\n",
    "num_workers=16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224), #무작위로 이미지를 크롭(잘라내고)하고 224*224 pixel로 크기 조정\n",
    "      transforms.RandomHorizontalFlip(), #이미지를 수평 방향으로 무작위로 뒤집기-데이터 다양성을 증가. 이미지 방향에 덜 민감\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서(pytorch 모델에서 처리할 수 있는 데이터 형식)로 변환. 이미지 데이터는 0에서 255 범위의 정수에서 0.0에서 1.0 범위의 부동소수점으로 스케일링\n",
    "      normalize,\n",
    "    ])\n",
    "\n",
    "valid_transform=transforms.Compose([\n",
    "      transforms.Resize(256), #모든 이미지의 크기를 256x256 픽셀로 조절한다.\n",
    "      transforms.CenterCrop(224), #중앙을 기준으로 224x224로 크롭하여 크기 조정\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서로 변환\n",
    "      normalize\n",
    "    ])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(traindir, train_transform) #traindir 이미지를 가져와서 train_transform 전처리를 거치고 이미지 데이터셋을 생성한다.\n",
    "\n",
    "valid_dataset=datasets.ImageFolder(valdir, valid_transform)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader( #데이터 로드 및 처리\n",
    "        train_dataset, #사용될 데이터셋\n",
    "        batch_size=batch_size, #모델에 한번에 공급될 샘플수\n",
    "        shuffle=True, #각 에프크(epoch) 시작시 데이터셋을 무작위로 섞어서 데이터의 순서에 의존하지 않도록 한다. overfitting을 방지한다.\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True) #Dataloader가 GPU에 복사하기 전에 CPU의 고정된 메모리 영역(pin된 메모리)에 로드하도록 한다. 이는 CPU에서 GPU로의 데이터 전송 속도를 향상시켜 학습 성능을 높인다.\n",
    "\n",
    "valid_loader=torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True)\n",
    "\n",
    "print(\"number of training dataset:%d\" % len(train_dataset))\n",
    "print(\"number of validation dataset:%d\" % len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **collect p for each layer for 100 samples after weight quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in valid_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    out, layerout = model(data)\n",
    "    break\n",
    "\n",
    "count = 0\n",
    "for k in layerout.keys():\n",
    "    if k.startswith('leaky'):\n",
    "        count += 1\n",
    "\n",
    "quant_p = np.zeros((100, count+1))\n",
    "batch = 0\n",
    "for data, target in valid_loader:\n",
    "    if train_on_gpu:\n",
    "        data, traget = data.cuda(), target.cuda()\n",
    "    out, layerout = model(data)\n",
    "    col = 0\n",
    "    for k in layerout.keys():\n",
    "        if k.startswith('leaky') or k=='conv19':\n",
    "            if batch == 0:\n",
    "                print(k)\n",
    "            _,p = quantize(layerout[k].cpu().detach().numpy())\n",
    "            quant_p[batch, col] = p\n",
    "            col += 1\n",
    "    batch += 1\n",
    "    if batch == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find most frequent clipping range\n",
    "def mode(X):\n",
    "    # X: List\n",
    "    return max(set(X), key=X.count)\n",
    "\n",
    "#create Lookup table\n",
    "cfg = []\n",
    "for i in range(quant_p.shape[1]):\n",
    "    print(i, mode(list(quant_p[:,i])))\n",
    "    cfg.append(int(mode(list(quant_p[:,i]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet19q(nn.Module): # formal inheritance method in PyTorch / inherit Parent class nn.Module\n",
    "    def __init__(self, p_list, num_classes: int = 1000): # 1000 is number of classes for neuralnet model to predict. It is default. you can reset it when calling the function\n",
    "        super(Darknet19q, self).__init__() # super(child class name, self).__init__()\n",
    "\n",
    "        self.p_list = p_list\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False) #3*3 require zero padding / 1*1 does not require zero padding\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32) #32개 channel 출력값을 normalization, Z function(평균, 분산)-->(0,1) gradient vanishing, exploding을 방지\n",
    "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.1) #Relu negative slope\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.leaky_relu2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.leaky_relu4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "        self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "        self.leaky_relu6 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm7 = nn.BatchNorm2d(128)\n",
    "        self.leaky_relu7 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm8 = nn.BatchNorm2d(256)\n",
    "        self.leaky_relu8 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm9 = nn.BatchNorm2d(512)\n",
    "        self.leaky_relu9 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm10 = nn.BatchNorm2d(256)\n",
    "        self.leaky_relu10 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm11 = nn.BatchNorm2d(512)\n",
    "        self.leaky_relu11 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm12 = nn.BatchNorm2d(256)\n",
    "        self.leaky_relu12 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv13 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm13 = nn.BatchNorm2d(512)\n",
    "        self.leaky_relu13 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm14 = nn.BatchNorm2d(1024)\n",
    "        self.leaky_relu14 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm15 = nn.BatchNorm2d(512)\n",
    "        self.leaky_relu15 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm16 = nn.BatchNorm2d(1024)\n",
    "        self.leaky_relu16 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm17 = nn.BatchNorm2d(512)\n",
    "        self.leaky_relu17 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm18 = nn.BatchNorm2d(1024)\n",
    "        self.leaky_relu18 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "        self.conv19 = nn.Conv2d(in_channels=1024, out_channels=num_classes, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.avgpool= nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.max_pool2d=nn.MaxPool2d(2, stride=2)\n",
    "    \n",
    "    def quantize(self, X, p=0, NBIT=8):\n",
    "        QRANGE = 2**(NBIT-1)\n",
    "        p = torch.tensor(p,dtype=torch.int8).to('cuda:0')\n",
    "        data_th = torch.clamp(X, -QRANGE*torch.float_power(2, -p),(QRANGE-1)*torch.float_power(2, -p))\n",
    "\n",
    "        SCALE = torch.float_power(2, -p)\n",
    "\n",
    "        data_qn = torch.round(data_th/SCALE)\n",
    "\n",
    "        data_dqn = data_qn*SCALE\n",
    "        return data_dqn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.batchnorm1(self.conv1(x))\n",
    "        out=self.leaky_relu1(out)\n",
    "        out=self.quantize(out, p=self.p_list[0])\n",
    "        out=self.max_pool2d(out)\n",
    "    \n",
    "        out=self.batchnorm2(self.conv2(out))\n",
    "        out=self.leaky_relu2(out)\n",
    "        out=self.quantize(out, p=self.p_list[1])\n",
    "        out=self.max_pool2d(out)\n",
    "    \n",
    "        out=self.batchnorm3(self.conv3(out))\n",
    "        out=self.leaky_relu3(out)\n",
    "        out=self.quantize(out, p=self.p_list[2])\n",
    "        out=self.batchnorm4(self.conv4(out))\n",
    "        out=self.leaky_relu4(out)\n",
    "        out = self.quantize(out, p=self.p_list[3])\n",
    "        out=self.batchnorm5(self.conv5(x))\n",
    "        out=self.leaky_relu5(out)\n",
    "        out=self.quantize(out, p=self.p_list[4])\n",
    "        out=self.max_pool2d(out)\n",
    "    \n",
    "        out=self.batchnorm6(self.conv6(x))\n",
    "        out=self.leaky_relu6(out)\n",
    "        out=self.quantize(out, p=self.p_list[5])\n",
    "        out=self.batchnorm7(self.conv7(x))\n",
    "        out=self.leaky_relu7(out)\n",
    "        out=self.quantize(out, p=self.p_list[6])\n",
    "        out=self.batchnorm8(self.conv8(x))\n",
    "        out=self.leaky_relu8(out)\n",
    "        out=self.quantize(out, p=self.p_list[7])\n",
    "        out=self.max_pool2d(out)\n",
    "    \n",
    "        out=self.batchnorm9(self.conv9(x))\n",
    "        out=self.leaky_relu9(out)\n",
    "        out=self.quantize(out, p=self.p_list[8])\n",
    "        out=self.batchnorm10(self.conv10(x))\n",
    "        out=self.leaky_relu10(out)\n",
    "        out=self.quantize(out, p=self.p_list[9])\n",
    "        out=self.batchnorm11(self.conv11(x))\n",
    "        out=self.leaky_relu11(out)\n",
    "        out=self.quantize(out, p=self.p_list[10])\n",
    "        out=self.batchnorm12(self.conv12(x))\n",
    "        out=self.leaky_relu12(out)\n",
    "        out=self.quantize(out, p=self.p_list[11])\n",
    "        out=self.batchnorm13(self.conv13(x))\n",
    "        out=self.leaky_relu13(out)\n",
    "        out=self.quantize(out, p=self.p_list[12])\n",
    "        out=self.max_pool2d(out)\n",
    "    \n",
    "        out=self.batchnorm14(self.conv14(x))\n",
    "        out=self.leaky_relu14(out)\n",
    "        out=self.quantize(out, p=self.p_list[13])\n",
    "        out=self.batchnorm15(self.conv15(x))\n",
    "        out=self.leaky_relu15(out)\n",
    "        out=self.quantize(out, p=self.p_list[14])\n",
    "        out=self.batchnorm16(self.conv16(x))\n",
    "        out=self.leaky_relu16(out)\n",
    "        out=self.quantize(out, p=self.p_list[15])\n",
    "        out=self.batchnorm17(self.conv17(x))\n",
    "        out=self.leaky_relu17(out)\n",
    "        out=self.quantize(out, p=self.p_list[16])\n",
    "        out=self.batchnorm18(self.conv18(x))\n",
    "        out=self.leaky_relu18(out)\n",
    "        out=self.quantize(out, p=self.p_list[17])\n",
    "    \n",
    "        out=self.conv19(out)\n",
    "        out=self.quantize(out, p=self.p_list[18])\n",
    "        out=self.avgpool(out)\n",
    "        out=torch.flatten(out,1)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy of dynamic quantized model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19q()\n",
    "#print(model)\n",
    "\n",
    "#weight_path = \"C:\\Bigdata\\\"quantization\\darknet19_224d.pth\"\n",
    "#model.Load_state_dict(torch.Load(weigtht_path, map_Location=torch.device('cpu')))\n",
    "\n",
    "weight_path = './darknet19_224d.pth'\n",
    "model.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #model.eval(): 모델을 평가 모드로 설정한다. \n",
    "             #이는 모델이 학습(training) 모드가 아닌, 평가(evaluation) 모드로 실행되어야 할 때 사용된다. \n",
    "             #평가 모드에서는 모델의 행동이 바뀌는 일부 레이어들(예를 들어, Dropout, BatchNorm 등)이 평가 상황에 적합하게 동작하도록 조정된다. \n",
    "             #예를 들어, Dropout 레이어는 학습 동안에는 일부 뉴런을 무작위로 비활성화하지만, 평가 모드에서는 모든 뉴런을 활성화 상태로 유지한다.\n",
    "\n",
    "model.cuda() #model.cuda(): 모델의 매개변수와 버퍼를 CUDA를 사용 가능한 GPU 메모리로 이동시킵니다. \n",
    "             #이를 통해 모델이 GPU에서 실행될 수 있게 하며, GPU의 병렬 처리 능력을 활용하여 더 빠른 계산이 가능해집니다. \n",
    "             #이 메소드를 호출하기 전에는 모델이 CPU 메모리에 있었을 것이고, 이 호출을 통해 모델의 연산이 GPU에서 수행되도록 변경됩니다.\n",
    "\n",
    "top1 = AverageMeter('Acc@1', ':6.4f') #batch 마다 평균을 구해서 그 정확도를 계산한다. 총 6자리를 표현하고 소수점 넷째자리까지 표시한다. Fixed point 형식으로 나타낸다\n",
    "                                      #3.141592 --> 3.1416\n",
    "top5 = AverageMeter('Acc@5', ':6.4f')\n",
    "for data, target in valid_loader: #배치 단위로 data와 target을 순회 \n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda() #data와 target을 GPU로 이동\n",
    "    #forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data) #model에 data 전달\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5)) #Top-1과 Top-5 정확도를 계산\n",
    "    top1.update(acc1.item(), target.size(0)) #acc1.item()은 Top-1 정확도의 스칼라 값을 반환, target.size(0)는 현재 배치의 크기를 의미\n",
    "    top5.update(acc5.item(), target.size(0)) \n",
    "\n",
    "##top1 accuracy, top5 accuracy\n",
    "print(top1, top5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **현재(향후) 연구 방향**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sensitivity Analysis and Mixed Precision**\n",
    "\n",
    "딥러닝 모델의 모든 층이 양자화에 똑같이 반응하는 것은 아니다.\n",
    "\n",
    "어떤 층은 presicion 저하에 좀 더 sensitive하고, 다른 층은 non-sensitive할 수 있다.\n",
    "\n",
    "따라서 각 층의 양자화에 대한 민감도(sensitivity)를 측정해서 그 민감도에 따라 다른 bit의 quantization을 구현할 수 있다.\n",
    "\n",
    "예를 들어 32bit, 16bit, 8bit, 4bit, 2bit등을 각 층에 따라 다르게 적용할 수 있다.\n",
    "\n",
    "sensitivity를 측정하는 방법과 mixed precision을 지원하는 하드웨어를 개발하는 것은 현재의 연구 방향이다. \n",
    "\n",
    "\n",
    "\n",
    "### **Quantization-Aware Training(QAT)\n",
    "\n",
    "부동수소점 32bit에서 8bit로의 변환에 따른 정밀도의 손실로 인해서 Post-Training quantization된 딥러닝 모델의 accuracy는 감소할 가능성이 크다.\n",
    "\n",
    "Quantization-Aware 양자화는 이러한 양자화에 따른 손실을 딥러닝 모델을 훈현시킬 때에 포함시키는 것이다.\n",
    "\n",
    "이를 위한 여러가지 방법들이 시도되고 있다.\n",
    "\n",
    "한가지 예로는 고정소수점 8비트로 모델을 재훈련시키는 것이다.\n",
    "\n",
    "모델의 모든 가중치는 32bit로 저장된다.\n",
    "\n",
    "Backward Propagation은 통상적인 방법으로 진행된다.\n",
    "\n",
    "그러나 forward pass에서 모델을 quantization시키고, 이에 따른 정확도를 기준으로 모델을 finetuning하게 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
