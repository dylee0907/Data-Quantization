{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weight-only quantization**\n",
    "\n",
    "딥러닝 모델은 신경망 아키텍처에 가중치(weights, layer parameters)를 포함하고 있다.\n",
    "\n",
    "딥러닝 모델에서 양자화는 가중치(weights, layer parameters)와 활성화(activations, layer output)에 대해서 가능하다.\n",
    "\n",
    "Weights를 양자화하면 모델의 크기를 줄일 수 있다.\n",
    "\n",
    "Activations를 양자화하면 모델 수행 속도를 향상시킬 수 있다.\n",
    "\n",
    "\n",
    "Weights 양자화는 딥러닝 모델에서 weights를 추출한 후에 이를 양자화시켜서 다시 딥러닝 모델에 업로드시키는 것이다.\n",
    "\n",
    "Tensor(layer)당 대칭 방식으로 양자화하는 방식으로, 전체 weights에 대해서 양자화하는 것은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import pickle\n",
    "#import time\n",
    "#import datetime\n",
    "import numpy as np #numpy 모듈을 불러온다\n",
    "import matplotlib.pyplot as plt #데이터 시각화 함수 제공\n",
    "\n",
    "import torch #Pytorch 라이브러리 기본 모듈, Tensor 연산과 자동 미분 지원\n",
    "import torch.nn as nn #신경망을 구축하는데 필요한 모든 구성 요소를 제공\n",
    "                      #이 모듈에는 레이어, activation 함수, loss function 등 신경망의 핵심 구성 요소가 포함되어 있음\n",
    "import torch.nn.functional as F #신경망을 구성할 때 사용되는 함수들의 모음\n",
    "                                #nn 모듈에 있는 클래스의 함수형 인터페이스를 제공(Activation function, loss function)\n",
    "#import torch.optim as optim // 모델의 weights를 최적화하는 데 사용되는 최적화 알고리즘들을 제공한다. ex) SGD, Adam과 같은 최적화 알고리즘 포함\n",
    "\n",
    "import torchvision.transforms as transforms #이미지 전처리에 사용되는 변환(transformations)을 제공 ex) 이미지를 tensor로 변환, 크기 조정, 정규화, 데이터 증강\n",
    "from torchvision import datasets #다양한 데이터셋을 가져온다. ex) MNIST, CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available! Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output: model output\n",
    "#target: correct answer\n",
    "#topk: number of k best model output\n",
    "\n",
    "def accuracy(output, target ,topk=(1,)):\n",
    "  \"\"\"\n",
    "  Computes the accuracy over the k top predictions for the specified values of k\n",
    "  IN top-5 accuracy you give yourself credit for having the right answer\n",
    "  if the right answer appears in your top five guesses\n",
    "  \"\"\"\n",
    "  with torch.no_grad(): #no need for gradient\n",
    "    maxk = max(topk) #store biggest topk value\n",
    "    batch_size=target.size(0) #check batch size // express \"target\" tensor's 0th dimension size\n",
    "\n",
    "    _, pred = output.topk(maxk,1,True,True) #maxk=bring upper k value / dim=selected class dimension / 1st True=largest, if smallest use False / 2nd True=sort result? yes=True, no=False\n",
    "    pred = pred.t() #transpose tensor pred\n",
    "\n",
    "    #correct = pred.eq(target. view(1, -1).expand_as(pred))\n",
    "    #correct = (pred == target.view(1, -1).expand_as(pred))\n",
    "    correct = (pred == target.unsqueeze(dim=0)).expand_as(pred)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      #correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul(1.0/batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "  def __init__(self, name, fmt=':f'): #floating point format\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.val=0\n",
    "    self.avg=0\n",
    "    self.sum=0\n",
    "    self.count=0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.num / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "    #fmtstr = '{name} {val' + self.fmt + '}({avg' + self.fmt+ '})'\n",
    "    fmtstr = '{name} ({avg' + self.fmt +  '})'\n",
    "\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def norm1(X,Y):\n",
    "  return np.sum(np.abs(X-Y))\n",
    "\n",
    "def norm2(X,Y):\n",
    "  return np.sqrt(np.sum(np.square(X-Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **define network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet19(nn.Module): # formal inheritance method in PyTorch / inherit Parent class nn.Module\n",
    "  def __init__(self, num_classes: int = 1000): # 1000 is number of classes for neuralnet model to predict. It is default. you can reset it when calling the function\n",
    "    super(Darknet19, self).__init__() # super(child class name, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False) #3*3 require zero padding / 1*1 does not require zero padding\n",
    "    self.batchnorm1 = nn.BatchNorm2d(32) #32개 channel 출력값을 normalization, Z function(평균, 분산)-->(0,1)\n",
    "    self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.1) #Relu negative slope\n",
    "\n",
    "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "    self.leaky_relu2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "    self.leaky_relu4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu6 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm7 = nn.BatchNorm2d(128)\n",
    "    self.leaky_relu7 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm8 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu8 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm9 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu9 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm10 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu10 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm11 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu11 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm12 = nn.BatchNorm2d(256)\n",
    "    self.leaky_relu12 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv13 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm13 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu13 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm14 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu14 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm15 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu15 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm16 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu16 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "    self.batchnorm17 = nn.BatchNorm2d(512)\n",
    "    self.leaky_relu17 = nn.LeakyReLU(negative_slope=0.1)\n",
    "    self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    self.batchnorm18 = nn.BatchNorm2d(1024)\n",
    "    self.leaky_relu18 = nn.LeakyReLU(negative_slope=0.1)\n",
    "\n",
    "    self.conv19 = nn.Conv2d(in_channels=1024, out_channels=num_classes, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "    self.avgpool= nn.AdaptiveAvgPool2d((1,1))\n",
    "    self.max_pool2d=nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out=self.batchnorm1(self.conv1(x))\n",
    "    out=self.leaky_relu1(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm2(self.conv2(x))\n",
    "    out=self.leaky_relu2(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm3(self.conv3(x))\n",
    "    out=self.leaky_relu3(out)\n",
    "    out=self.batchnorm4(self.conv4(x))\n",
    "    out=self.leaky_relu4(out)\n",
    "    out=self.batchnorm5(self.conv5(x))\n",
    "    out=self.leaky_relu5(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm6(self.conv6(x))\n",
    "    out=self.leaky_relu6(out)\n",
    "    out=self.batchnorm7(self.conv7(x))\n",
    "    out=self.leaky_relu7(out)\n",
    "    out=self.batchnorm8(self.conv8(x))\n",
    "    out=self.leaky_relu8(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm9(self.conv9(x))\n",
    "    out=self.leaky_relu9(out)\n",
    "    out=self.batchnorm10(self.conv10(x))\n",
    "    out=self.leaky_relu10(out)\n",
    "    out=self.batchnorm11(self.conv11(x))\n",
    "    out=self.leaky_relu11(out)\n",
    "    out=self.batchnorm12(self.conv12(x))\n",
    "    out=self.leaky_relu12(out)\n",
    "    out=self.batchnorm13(self.conv13(x))\n",
    "    out=self.leaky_relu13(out)\n",
    "    out=self.max_pool2d(out)\n",
    "\n",
    "    out=self.batchnorm14(self.conv14(x))\n",
    "    out=self.leaky_relu14(out)\n",
    "    out=self.batchnorm15(self.conv15(x))\n",
    "    out=self.leaky_relu15(out)\n",
    "    out=self.batchnorm16(self.conv16(x))\n",
    "    out=self.leaky_relu16(out)\n",
    "    out=self.batchnorm17(self.conv17(x))\n",
    "    out=self.leaky_relu17(out)\n",
    "    out=self.batchnorm18(self.conv18(x))\n",
    "    out=self.leaky_relu18(out)\n",
    "\n",
    "    out=self.conv19(out)\n",
    "    out=self.avgpool(out)\n",
    "    out=torch.flatten(out,1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19()\n",
    "#print(model)\n",
    "\n",
    "#weight_path = \"C:\\Bigdata\\\"quantization\\darknet19_224d.pth\"\n",
    "#model.Load_state_dict(torch.Load(weigtht_path, map_Location=torch.device('cpu')))\n",
    "\n",
    "weight_path = './darknet19_224d.pth'\n",
    "model.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\\wrk\\xsjhdnobkup5\\taeheej\\dataset\\imagenet\"\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val3k')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1,1,1]) #scale[0,1]--->normalization unpreceded\n",
    "\n",
    "batch_size=32\n",
    "num_workers=16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224), #무작위로 이미지를 크롭(잘라내고)하고 224*224 pixel로 크기 조정\n",
    "      transforms.RandomHorizontalFlip(), #이미지를 수평 방향으로 무작위로 뒤집기-데이터 다양성을 증가. 이미지 방향에 덜 민감\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서(pytorch 모델에서 처리할 수 있는 데이터 형식)로 변환. 이미지 데이터는 0에서 255 범위의 정수에서 0.0에서 1.0 범위의 부동소수점으로 스케일링\n",
    "      normalize,\n",
    "    ])\n",
    "\n",
    "valid_transform=transforms.Compose([\n",
    "      transforms.Resize(256), #모든 이미지의 크기를 256x256 픽셀로 조절한다.\n",
    "      transforms.CenterCrop(224), #중앙을 기준으로 224x224로 크롭하여 크기 조정\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서로 변환\n",
    "      normalize\n",
    "    ])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(traindir, train_transform) #traindir 이미지를 가져와서 train_transform 전처리를 거치고 이미지 데이터셋을 생성한다.\n",
    "\n",
    "valid_dataset=datasets.ImageFolder(valdir, valid_transform)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader( #데이터 로드 및 처리\n",
    "        train_dataset, #사용될 데이터셋\n",
    "        batch_size=batch_size, #모델에 한번에 공급될 샘플수\n",
    "        shuffle=True, #각 에프크(epoch) 시작시 데이터셋을 무작위로 섞어서 데이터의 순서에 의존하지 않도록 한다. overfitting을 방지한다.\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True) #Dataloader가 GPU에 복사하기 전에 CPU의 고정된 메모리 영역(pin된 메모리)에 로드하도록 한다. 이는 CPU에서 GPU로의 데이터 전송 속도를 향상시켜 학습 성능을 높인다.\n",
    "\n",
    "valid_loader=torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True)\n",
    "\n",
    "print(\"number of training dataset:%d\" % len(train_dataset))\n",
    "print(\"number of validation dataset:%d\" % len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy of floating point32 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #model.eval(): 모델을 평가 모드로 설정한다. \n",
    "             #이는 모델이 학습(training) 모드가 아닌, 평가(evaluation) 모드로 실행되어야 할 때 사용된다. \n",
    "             #평가 모드에서는 모델의 행동이 바뀌는 일부 레이어들(예를 들어, Dropout, BatchNorm 등)이 평가 상황에 적합하게 동작하도록 조정된다. \n",
    "             #예를 들어, Dropout 레이어는 학습 동안에는 일부 뉴런을 무작위로 비활성화하지만, 평가 모드에서는 모든 뉴런을 활성화 상태로 유지한다.\n",
    "\n",
    "model.cuda() #model.cuda(): 모델의 매개변수와 버퍼를 CUDA를 사용 가능한 GPU 메모리로 이동시킵니다. \n",
    "             #이를 통해 모델이 GPU에서 실행될 수 있게 하며, GPU의 병렬 처리 능력을 활용하여 더 빠른 계산이 가능해집니다. \n",
    "             #이 메소드를 호출하기 전에는 모델이 CPU 메모리에 있었을 것이고, 이 호출을 통해 모델의 연산이 GPU에서 수행되도록 변경됩니다.\n",
    "\n",
    "top1 = AverageMeter('Acc@1', ':6.4f') #batch 마다 평균을 구해서 그 정확도를 계산한다. 총 6자리를 표현하고 소수점 넷째자리까지 표시한다. Fixed point 형식으로 나타낸다\n",
    "                                      #3.141592 --> 3.1416\n",
    "top5 = AverageMeter('Acc@5', ':6.4f')\n",
    "for data, target in valid_loader: #배치 단위로 data와 target을 순회 \n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda() #data와 target을 GPU로 이동\n",
    "    #forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data) #model에 data 전달\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5)) #Top-1과 Top-5 정확도를 계산\n",
    "    top1.update(acc1.item(), target.size(0)) #acc1.item()은 Top-1 정확도의 스칼라 값을 반환, target.size(0)는 현재 배치의 크기를 의미\n",
    "    top5.update(acc5.item(), target.size(0)) \n",
    "\n",
    "##top1 accuracy, top5 accuracy\n",
    "print(top1, top5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **find eligible layers for quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 코드는 결국 어떤 layer를 quantization 할것인지 정하는 부분\n",
    "\n",
    "disallowed_layer_names = [] #특정 레이어 제고를 위해 사용, 나중에 빼고싶은 레이어 이름 추가 가능\n",
    "\n",
    "#Linear operation, convolution, batchnorm\n",
    "whitelist=[torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, torch.nn.Conv3d, nn.BatchNorm2d] #linear=fully connected\n",
    "whitelist_layer_types = tuple(whitelist) #whitelist 리스트를 튜플로 변환(튜플은 리스트와 유사하지만 변경 불가)\n",
    "eligible_modules_list=[]\n",
    "eligible_param_list=[]\n",
    "for name, mod in model.named_modules(): #name=모듈이름, mod=모듈 자체\n",
    "    if isinstance(mod, whitelist_layer_types) and name not in disallowed_layer_names: # ifinstance = mod가 whitelist_layer_types에 정의된 레이어 타입 중 하나인지 확인 \n",
    "                                                                                      # 해당 모듈의 이름이 disallowed_layer_names 리스트에 없는지 확인\n",
    "        eligible_modules_list.append((name, mod)) #조건을 만족하는 모듈 이름과 모듈 자체를 리스트에 추가\n",
    "        eligible_param_list.append(name)\n",
    "\n",
    "print(eligible_param_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantization in Deep Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(X, NBIT=8):\n",
    "    #symmetry quantization, per tensor\n",
    "    #1. find threshold\n",
    "    threshold = np.max([np.abs(np.max(X)), np.abs(np.min(X))])\n",
    "\n",
    "    QRANGE = 2**(NBIT-1)\n",
    "\n",
    "    #2. find p: decimal position of quantized value\n",
    "    p = np.int(np.log2((QRANGE-1)/threshold))\n",
    "\n",
    "    #3. quantize using 8 bit\n",
    "    #3.1 apply threshold\n",
    "    data_th = np.clip(X, -QRANGE*2**(-p), (QRANGE-1)*2**(-p))\n",
    "\n",
    "    #3.2 calculate the scale factor for quantization\n",
    "    SCALE = 2**(-p)\n",
    "\n",
    "    #3.3 quantize (apply scale factor)\n",
    "    #we are using a rounding function to force the quantized values to be the whole numbers which INT8 can represent\n",
    "    data_qn = np.round(data_th/SCALE)\n",
    "\n",
    "    #3.4 dequantize (simply reverse the quantization)\n",
    "    data_dqn = data_qn *SCALE\n",
    "    return data_dqn, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def quantize_asymmetric(X, NBIT=8):\n",
    "    # Asymmetric quantization\n",
    "#    QRANGE = 2**NBIT - 1\n",
    "\n",
    "    # 1. Calculate min and max values\n",
    "#    data_min = np.min(X)\n",
    "#    data_max = np.max(X)\n",
    "\n",
    "    # 2. Calculate scale and zero-point\n",
    "#    scale = (data_max - data_min) / QRANGE\n",
    "#    zero_point = np.round(-data_min / scale)\n",
    "\n",
    "    # 3. Quantize\n",
    "#    data_qn = np.round(X / scale + zero_point)\n",
    "\n",
    "    # 4. Clip values to ensure they are within the valid range\n",
    "#    data_qn = np.clip(data_qn, 0, QRANGE)\n",
    "\n",
    "    # 5. Dequantize\n",
    "#    data_dqn = (data_qn - zero_point) * scale\n",
    "#    return data_dqn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. extract weight\n",
    "#2, quantize weight\n",
    "#3. Load quantized weight into the model\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    layername = '.'.join(name.split('.')[:1]) #파라미터 이름에서 첫 번째 부분만을 추출하여 레이어의 이름을 얻는다 ex) conv1.weight -->conv1 추출\n",
    "\n",
    "    if (layername in eligible_param_list) and (len(param.size()) in [1, 2, 4]): #현재 parameter 차원이 1,2,4 차원인지 확인한다\n",
    "        #1차원 tensor = bias ex) nn.Linear(20, 10) layer는 20개의 입력 특징, 10개의 출력 뉴런. 이 layer의 bias는 10개의 요소를 갖는 1차원 텐서, 각 출력 뉴런에 대한 bias를 나타냄\n",
    "        #2차원 tensor = fully connnected layer weight ex) nn.Linear(20, 10) layer의 weight는 10x20 크기의 2차원 tesnor로 20개 입력 틍징과 10개의 출력 뉴런 사이의 연결 강도 나타냄\n",
    "        #4차원 tensor = convolution layer weight ex) nn.Conv2d(3,6,5) layer는 3개의 입력 channel, 6개의 출력 channel, 5x5 kernel을 갖는다. 이 Layer의 weight는 6x3x5x5 크기의 4차원 tensor임\n",
    "        weight = param.cpu().detach().numpy() #parameter을 CPU로 이동시키고(param.cpu()), gradient 계산에서 분리(detach)하여 Numpy 배열로 변환\n",
    "        dqn, _ = quantize(weight) #양자화된 data와 Scale factor를 반환, Scale factor는 사용 안하므로 '_'로 무시\n",
    "        param.data = torch.from_numpy(dqn) #양자화된 데이터(dpn)를 다시 PyTorch Tensor로 변환하여 원래 parameter의 data에 할당(해당 파라미터를 양자화된 겂으로 업데이트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "top1 = AverageMeter('Acc@1', ':6.4f')\n",
    "top5 = AverageMeter('Acc@5', ':6.4f')\n",
    "for data, target in valid_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    #forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1,5))\n",
    "    top1.update(acc1.item(), target.size(0))\n",
    "    top5.update(acc5.item(), target.size(0))\n",
    "\n",
    "print(top1, top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weight quantized model\n",
    "torch.save(model.state_dict(), './darknet19_quan_weight1.pth') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
