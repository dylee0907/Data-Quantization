{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Post-Training Dynamic Quantization**\n",
    "\n",
    "딥러닝 모델의 각 층(layer)의 Activation을 모델의 inference 중에 quantization시키는 것을 dynamic quantization이라고 부른다.\n",
    "\n",
    "딥러닝의 입력 Tensor value에 따라 quantization parameter(clipping range)가 달라질 수 있고, 따라서 입력 텐서값에 따라 clippling range를 보정해주는 것이 dynamic quantization이다.\n",
    "\n",
    "각 층의 activation후에 quantization layer를 추가하면 된다.\n",
    "\n",
    "Activation 전에 quantization을 할 수도 있지만, 이 경우 quantization threshold가 증가하고, 따라서 quantization step이 증가되어 quantization loss가 커질 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import pickle\n",
    "#import time\n",
    "#import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available. Training on CPU ...')\n",
    "\n",
    "else:\n",
    "    print('CUDA is available! Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output: model output\n",
    "#target: correct answer\n",
    "#topk: number of k best model output\n",
    "\n",
    "def accuracy(output, target ,topk=(1,)):\n",
    "  \"\"\"\n",
    "  Computes the accuracy over the k top predictions for the specified values of k\n",
    "  IN top-5 accuracy you give yourself credit for having the right answer\n",
    "  if the right answer appears in your top five guesses\n",
    "  \"\"\"\n",
    "  with torch.no_grad(): #no need for gradient\n",
    "    maxk = max(topk) #store biggest topk value\n",
    "    batch_size=target.size(0) #check batch size // express \"target\" tensor's 0th dimension size\n",
    "\n",
    "    _, pred = output.topk(maxk,1,True,True) #maxk=bring upper k value / dim=selected class dimension / 1st True=largest, if smallest use False / 2nd True=sort result? yes=True, no=False\n",
    "    pred = pred.t() #transpose tensor pred\n",
    "\n",
    "    #correct = pred.eq(target. view(1, -1).expand_as(pred))\n",
    "    #correct = (pred == target.view(1, -1).expand_as(pred))\n",
    "    correct = (pred == target.unsqueeze(dim=0)).expand_as(pred)\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      #correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul(1.0/batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "  def __init__(self, name, fmt=':f'): #floating point format\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.val=0\n",
    "    self.avg=0\n",
    "    self.sum=0\n",
    "    self.count=0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.num / self.count\n",
    "\n",
    "  def __str__(self):\n",
    "    #fmtstr = '{name} {val' + self.fmt + '}({avg' + self.fmt+ '})'\n",
    "    fmtstr = '{name} ({avg' + self.fmt +  '})'\n",
    "\n",
    "    return fmtstr.format(**self.__dict__)\n",
    "\n",
    "def norm1(X,Y):\n",
    "  return np.sum(np.abs(X-Y))\n",
    "\n",
    "def norm2(X,Y):\n",
    "  return np.sqrt(np.sum(np.square(X-Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Dynamic Quantized Model After Activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet19q1(nn.Module):\n",
    "    #quantized model after activation\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(Darknet19q1, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm8 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm9 = nn.BatchNorm2d(512)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm10 = nn.BatchNorm2d(256)\n",
    "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm11 = nn.BatchNorm2d(512)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm12 = nn.BatchNorm2d(256)\n",
    "        self.conv13 = nn.Conv2d(in_channels=256, out_channels=512,kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm13 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm14 = nn.BatchNorm2d(1024)\n",
    "        self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm15 = nn.BatchNorm2d(512)\n",
    "        self.conv16 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm16 = nn.BatchNorm2d(1024)\n",
    "        self.conv17 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm17 = nn.BatchNorm2d(512)\n",
    "        self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm18 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.conv19 = nn.Conv2d(in_channels=1024, out_channels=num_classes, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    def quantize(self, X, NBIT=8):\n",
    "        # 1. find threshold(maximum range)\n",
    "        threshold = torch.maximum(X.max().abs(), X.min().abs())\n",
    "        QRANGE = 2**(NBIT-1)\n",
    "        # 2. find p: decimal position of quantized value\n",
    "        p = torch.log2((QRANGE-1)/threshold).int()\n",
    "\n",
    "        # 3. quantize using 8 bit\n",
    "        # 3.1 apply thresholds\n",
    "        data_th = torch.clamp(X, -QRANGE*torch.float_power(2, -p), (QRANGE-1)*torch.float_power(2,-p))\n",
    "\n",
    "        # 3.2 calculate the scale factor for quantization\n",
    "        SCALE = torch.float_power(2,-p)\n",
    "\n",
    "        # 3.3 quantize(apply scale factor)\n",
    "        #we are using a rounding function to force the quantized values to be the whole numbers which INT8 can represent\n",
    "        data_qn = torch.round(data_th/SCALE)\n",
    "        #torch.round(data_th/SCALE, deciamls=3)\n",
    "\n",
    "        # 3.4 dequantize(simply the reverse quantization)\n",
    "        data_dqn = data_qn*SCALE\n",
    "        return data_dqn\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.batchnorm1(self.conv1(x))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = self.batchnorm2(self.conv2(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = self.batchnorm3(self.conv3(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm4(self.conv4(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm5(self.conv5(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = self.batchnorm6(self.conv6(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm7(self.conv7(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm8(self.conv8(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = self.batchnorm9(self.conv9(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm10(self.conv10(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm11(self.conv11(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm12(self.conv12(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm13(self.conv13(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = self.batchnorm14(self.conv14(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm15(self.conv15(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm16(self.conv16(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm17(self.conv17(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "        out = self.batchnorm18(self.conv18(out))\n",
    "        out = F.leaky_relu(out, negative_slope=0.1)\n",
    "        out = self.quantize(out)\n",
    "\n",
    "        out = self.conv19(out)\n",
    "        out = self.quantize(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet19q1()\n",
    "#print(model)\n",
    "\n",
    "#weight_path = \"C:\\Bigdata\\\"quantization\\darknet19_224d.pth\"\n",
    "#model.Load_state_dict(torch.Load(weigtht_path, map_Location=torch.device('cpu')))\n",
    "\n",
    "weight_path = './darknet19_224d.pth'\n",
    "model.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\\wrk\\xsjhdnobkup5\\taeheej\\dataset\\imagenet\"\n",
    "traindir = os.path.join(data_path, 'train')\n",
    "valdir = os.path.join(data_path, 'val3k')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1,1,1]) #scale[0,1]--->normalization unpreceded\n",
    "\n",
    "batch_size=32\n",
    "num_workers=16\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224), #무작위로 이미지를 크롭(잘라내고)하고 224*224 pixel로 크기 조정\n",
    "      transforms.RandomHorizontalFlip(), #이미지를 수평 방향으로 무작위로 뒤집기-데이터 다양성을 증가. 이미지 방향에 덜 민감\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서(pytorch 모델에서 처리할 수 있는 데이터 형식)로 변환. 이미지 데이터는 0에서 255 범위의 정수에서 0.0에서 1.0 범위의 부동소수점으로 스케일링\n",
    "      normalize,\n",
    "    ])\n",
    "\n",
    "valid_transform=transforms.Compose([\n",
    "      transforms.Resize(256), #모든 이미지의 크기를 256x256 픽셀로 조절한다.\n",
    "      transforms.CenterCrop(224), #중앙을 기준으로 224x224로 크롭하여 크기 조정\n",
    "      transforms.ToTensor(), #이미지를 pytorch 텐서로 변환\n",
    "      normalize\n",
    "    ])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(traindir, train_transform) #traindir 이미지를 가져와서 train_transform 전처리를 거치고 이미지 데이터셋을 생성한다.\n",
    "\n",
    "valid_dataset=datasets.ImageFolder(valdir, valid_transform)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader( #데이터 로드 및 처리\n",
    "        train_dataset, #사용될 데이터셋\n",
    "        batch_size=batch_size, #모델에 한번에 공급될 샘플수\n",
    "        shuffle=True, #각 에프크(epoch) 시작시 데이터셋을 무작위로 섞어서 데이터의 순서에 의존하지 않도록 한다. overfitting을 방지한다.\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True) #Dataloader가 GPU에 복사하기 전에 CPU의 고정된 메모리 영역(pin된 메모리)에 로드하도록 한다. 이는 CPU에서 GPU로의 데이터 전송 속도를 향상시켜 학습 성능을 높인다.\n",
    "\n",
    "valid_loader=torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True)\n",
    "\n",
    "print(\"number of training dataset:%d\" % len(train_dataset))\n",
    "print(\"number of validation dataset:%d\" % len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Accuracy of Dynamic Quantized Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #model.eval(): 모델을 평가 모드로 설정한다. \n",
    "             #이는 모델이 학습(training) 모드가 아닌, 평가(evaluation) 모드로 실행되어야 할 때 사용된다. \n",
    "             #평가 모드에서는 모델의 행동이 바뀌는 일부 레이어들(예를 들어, Dropout, BatchNorm 등)이 평가 상황에 적합하게 동작하도록 조정된다. \n",
    "             #예를 들어, Dropout 레이어는 학습 동안에는 일부 뉴런을 무작위로 비활성화하지만, 평가 모드에서는 모든 뉴런을 활성화 상태로 유지한다.\n",
    "\n",
    "model.cuda() #model.cuda(): 모델의 매개변수와 버퍼를 CUDA를 사용 가능한 GPU 메모리로 이동시킵니다. \n",
    "             #이를 통해 모델이 GPU에서 실행될 수 있게 하며, GPU의 병렬 처리 능력을 활용하여 더 빠른 계산이 가능해집니다. \n",
    "             #이 메소드를 호출하기 전에는 모델이 CPU 메모리에 있었을 것이고, 이 호출을 통해 모델의 연산이 GPU에서 수행되도록 변경됩니다.\n",
    "\n",
    "top1 = AverageMeter('Acc@1', ':6.4f') #batch 마다 평균을 구해서 그 정확도를 계산한다. 총 6자리를 표현하고 소수점 넷째자리까지 표시한다. Fixed point 형식으로 나타낸다\n",
    "                                      #3.141592 --> 3.1416\n",
    "top5 = AverageMeter('Acc@5', ':6.4f')\n",
    "for data, target in valid_loader: #배치 단위로 data와 target을 순회 \n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda() #data와 target을 GPU로 이동\n",
    "    #forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data) #model에 data 전달\n",
    "    acc1, acc5 = accuracy(output, target, topk=(1, 5)) #Top-1과 Top-5 정확도를 계산\n",
    "    top1.update(acc1.item(), target.size(0)) #acc1.item()은 Top-1 정확도의 스칼라 값을 반환, target.size(0)는 현재 배치의 크기를 의미\n",
    "    top5.update(acc5.item(), target.size(0)) \n",
    "\n",
    "##top1 accuracy, top5 accuracy\n",
    "print(top1, top5)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
